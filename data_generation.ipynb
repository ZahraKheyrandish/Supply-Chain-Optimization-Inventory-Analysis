{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVGa7GKYjWOfH5WBSjFHBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZahraKheyrandish/Supply-Chain-Optimization-Inventory-Analysis/blob/main/data_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiQcajlatW-s",
        "outputId": "acb4b059-7df6-484c-b5db-eaff1e88c62c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Faker in /usr/local/lib/python3.11/dist-packages (37.4.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from Faker) (2025.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "0iauelW6tXCB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake = Faker('en_US')\n",
        "Faker.seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "metadata": {
        "id": "TWdIgDeItXEI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_seasonal_factor(date: datetime) -> float:\n",
        "    \"\"\"\n",
        "    Calculates a seasonal factor based on the month.\n",
        "    Boosts sales in winter months, slightly dips in summer.\n",
        "\n",
        "    Args:\n",
        "        date (datetime): The date for which to calculate the seasonal factor.\n",
        "\n",
        "    Returns:\n",
        "        float: The seasonal factor.\n",
        "    \"\"\"\n",
        "    month = date.month\n",
        "    if month in [12, 1, 2]:\n",
        "        return 1.5\n",
        "    elif month in [7, 8]:\n",
        "        return 0.8\n",
        "    return 1.0\n"
      ],
      "metadata": {
        "id": "mJfgRXCRtXLk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_products_df(num_products: int, faker_instance: Faker) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic product data for a pharmaceutical company.\n",
        "\n",
        "    Args:\n",
        "        num_products (int): The number of unique products to generate.\n",
        "        faker_instance (Faker): An instance of the Faker library for generating names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing product_id, product_name, product_category,\n",
        "                      unit_price, avg_shelf_life_days, and storage_conditions.\n",
        "    \"\"\"\n",
        "    product_ids = [f'PROD_{i:05d}' for i in range(1, num_products + 1)]\n",
        "    product_categories = [\n",
        "        'Antibiotics', 'Pain Relievers', 'Anti-Inflammatories', 'Vitamins & Supplements',\n",
        "        'Cardiovascular', 'Gastrointestinal', 'Respiratory', 'Neurological',\n",
        "        'Dermatological', 'Ophthalmic & Otic', 'Diabetic Care', 'Hormonal',\n",
        "        'Herbal Remedies', 'Disposable Medical Devices'\n",
        "    ]\n",
        "    product_names = []\n",
        "    for _ in range(num_products):\n",
        "        if random.random() < 0.7:\n",
        "            product_names.append(f'{random.choice([\"Tablet\", \"Capsule\", \"Syrup\", \"Ointment\", \"Ampoule\", \"Drop\", \"Cream\"])} {faker_instance.word()} {faker_instance.word()}')\n",
        "        else:\n",
        "            product_names.append(f'{\"\".join(random.choices(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", k=2))}-{random.randint(100,999)} {random.choice([\"mg\", \"g\", \"ml\", \"unit\"])} {faker_instance.word()}')\n",
        "\n",
        "    unit_prices = np.round(np.random.lognormal(mean=np.log(20), sigma=0.8, size=num_products), 2)\n",
        "    unit_prices = np.maximum(unit_prices, 1.00)\n",
        "    shelf_life_days = np.random.choice([365, 730, 1095, 1460, 1825], size=num_products, p=[0.1, 0.4, 0.3, 0.1, 0.1])\n",
        "    storage_conditions = np.random.choice(['Room Temperature', 'Cold Storage', 'Protect from Light/Moisture', 'Refrigerated (2-8Â°C)'], size=num_products, p=[0.6, 0.2, 0.1, 0.1])\n",
        "\n",
        "    products_df = pd.DataFrame({\n",
        "        'product_id': product_ids,\n",
        "        'product_name': product_names,\n",
        "        'product_category': np.random.choice(product_categories, size=num_products),\n",
        "        'unit_price': unit_prices,\n",
        "        'avg_shelf_life_days': shelf_life_days,\n",
        "        'storage_conditions': storage_conditions\n",
        "    })\n",
        "    products_df['product_category'] = products_df['product_category'].astype('category')\n",
        "    products_df['storage_conditions'] = products_df['storage_conditions'].astype('category')\n",
        "    return products_df"
      ],
      "metadata": {
        "id": "GwwuukSAtXOB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_warehouses_df(num_warehouses: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic warehouse data.\n",
        "\n",
        "    Args:\n",
        "        num_warehouses (int): The number of warehouses to generate.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing warehouse_id, warehouse_name, warehouse_city,\n",
        "                      latitude, longitude, and capacity_units.\n",
        "    \"\"\"\n",
        "    warehouse_ids = [f'WH_{i:02d}' for i in range(1, num_warehouses + 1)]\n",
        "    warehouse_locations = {\n",
        "        'Tehran': {'lat': 35.6892, 'lon': 51.3890}, 'Mashhad': {'lat': 36.2605, 'lon': 59.6168},\n",
        "        'Isfahan': {'lat': 32.6546, 'lon': 51.6670}, 'Tabriz': {'lat': 38.0805, 'lon': 46.2918},\n",
        "        'Shiraz': {'lat': 29.6065, 'lon': 52.5414}, 'Ahvaz': {'lat': 31.3204, 'lon': 48.6720},\n",
        "        'Karaj': {'lat': 35.8322, 'lon': 50.9667}, 'Rasht': {'lat': 37.2752, 'lon': 49.5891},\n",
        "        'Kerman': {'lat': 30.2832, 'lon': 57.0671}, 'Bandar Abbas': {'lat': 27.1887, 'lon': 56.2829}\n",
        "    }\n",
        "    warehouse_names = [f'Central Warehouse {city}' for city in warehouse_locations.keys()]\n",
        "    warehouse_latitudes = [loc['lat'] for loc in warehouse_locations.values()]\n",
        "    warehouse_longitudes = [loc['lon'] for loc in warehouse_locations.values()]\n",
        "    capacity_units = np.random.randint(1_000_000, 5_000_000, size=num_warehouses)\n",
        "    capacity_units[0] = np.random.randint(4_000_000, 7_000_000)\n",
        "\n",
        "    warehouses_df = pd.DataFrame({\n",
        "        'warehouse_id': warehouse_ids,\n",
        "        'warehouse_name': warehouse_names,\n",
        "        'warehouse_city': list(warehouse_locations.keys()),\n",
        "        'latitude': warehouse_latitudes,\n",
        "        'longitude': warehouse_longitudes,\n",
        "        'capacity_units': capacity_units\n",
        "    })\n",
        "    warehouses_df['warehouse_city'] = warehouses_df['warehouse_city'].astype('category')\n",
        "    return warehouses_df"
      ],
      "metadata": {
        "id": "2DgLCaImtXTE"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_suppliers_df(num_suppliers: int, faker_instance: Faker) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic supplier data.\n",
        "\n",
        "    Args:\n",
        "        num_suppliers (int): The number of suppliers to generate.\n",
        "        faker_instance (Faker): An instance of the Faker library for generating names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing supplier_id, supplier_name, supplier_location,\n",
        "                      avg_lead_time_days, and reliability_score.\n",
        "    \"\"\"\n",
        "    supplier_ids = [f'SUP_{i:03d}' for i in range(1, num_suppliers + 1)]\n",
        "    supplier_names = [faker_instance.company() for _ in range(num_suppliers)]\n",
        "    supplier_locations = [faker_instance.city() for _ in range(num_suppliers)]\n",
        "    avg_lead_time_days = np.random.randint(5, 30, size=num_suppliers)\n",
        "    reliability_scores = np.round(np.random.uniform(0.7, 0.99, size=num_suppliers), 2)\n",
        "\n",
        "    suppliers_df = pd.DataFrame({\n",
        "        'supplier_id': supplier_ids,\n",
        "        'supplier_name': supplier_names,\n",
        "        'supplier_location': supplier_locations,\n",
        "        'avg_lead_time_days': avg_lead_time_days,\n",
        "        'reliability_score': reliability_scores\n",
        "    })\n",
        "    suppliers_df['supplier_location'] = suppliers_df['supplier_location'].astype('category')\n",
        "    return suppliers_df"
      ],
      "metadata": {
        "id": "LuOk_tcotXVU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_purchase_orders_df(num_purchase_orders: int, products_df: pd.DataFrame, suppliers_df: pd.DataFrame, start_date: datetime, end_date: datetime) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic purchase order data.\n",
        "\n",
        "    Args:\n",
        "        num_purchase_orders (int): The number of purchase orders to generate.\n",
        "        products_df (pd.DataFrame): DataFrame of product master data.\n",
        "        suppliers_df (pd.DataFrame): DataFrame of supplier master data.\n",
        "        start_date (datetime): The start date for generating POs.\n",
        "        end_date (datetime): The end date for generating POs.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing po_id, po_date, supplier_id, product_id,\n",
        "                      ordered_quantity, unit_cost, expected_delivery_date, actual_delivery_date,\n",
        "                      and delivery_status.\n",
        "    \"\"\"\n",
        "    po_data = []\n",
        "    for i in range(num_purchase_orders):\n",
        "        po_id = f'PO_{i:05d}'\n",
        "        po_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
        "\n",
        "        product = products_df.sample(1).iloc[0]\n",
        "        supplier = suppliers_df.sample(1, weights='reliability_score').iloc[0]\n",
        "\n",
        "        base_quantity = np.random.randint(500, 5000)\n",
        "        ordered_quantity = max(10, int(base_quantity / (product['unit_price'] / 10 + 1)))\n",
        "        unit_cost = product['unit_price'] * np.random.uniform(0.5, 0.8)\n",
        "        expected_delivery_date = po_date + timedelta(days=int(supplier['avg_lead_time_days']))\n",
        "\n",
        "        delivery_delay_days = 0\n",
        "        if random.random() < (1 - supplier['reliability_score']):\n",
        "            delivery_delay_days = np.random.randint(1, 10)\n",
        "            if random.random() < 0.2:\n",
        "                delivery_delay_days = np.random.randint(10, 30)\n",
        "\n",
        "        actual_delivery_date = expected_delivery_date + timedelta(days=int(delivery_delay_days))\n",
        "\n",
        "        delivery_status = 'Delivered'\n",
        "        if actual_delivery_date > end_date:\n",
        "            delivery_status = 'Pending'\n",
        "        elif actual_delivery_date > expected_delivery_date:\n",
        "            delivery_status = 'Delayed'\n",
        "\n",
        "        po_data.append({\n",
        "            'po_id': po_id,\n",
        "            'po_date': po_date,\n",
        "            'supplier_id': supplier['supplier_id'],\n",
        "            'product_id': product['product_id'],\n",
        "            'ordered_quantity': ordered_quantity,\n",
        "            'unit_cost': unit_cost,\n",
        "            'expected_delivery_date': expected_delivery_date,\n",
        "            'actual_delivery_date': actual_delivery_date,\n",
        "            'delivery_status': delivery_status\n",
        "        })\n",
        "\n",
        "    purchase_orders_df = pd.DataFrame(po_data)\n",
        "    purchase_orders_df['po_date'] = pd.to_datetime(purchase_orders_df['po_date'])\n",
        "    purchase_orders_df['expected_delivery_date'] = pd.to_datetime(purchase_orders_df['expected_delivery_date'])\n",
        "    purchase_orders_df['actual_delivery_date'] = pd.to_datetime(purchase_orders_df['actual_delivery_date'])\n",
        "    purchase_orders_df['delivery_status'] = purchase_orders_df['delivery_status'].astype('category')\n",
        "    return purchase_orders_df\n",
        "\n"
      ],
      "metadata": {
        "id": "X8EQAYKjtXX6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_customers_df(num_customers: int, faker_instance: Faker) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic customer (pharmacy) data.\n",
        "\n",
        "    Args:\n",
        "        num_customers (int): The number of customers to generate.\n",
        "        faker_instance (Faker): An instance of the Faker library for generating names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing customer_id, customer_name, and customer_location.\n",
        "    \"\"\"\n",
        "    customer_ids = [f'CUST_{i:04d}' for i in range(1, num_customers + 1)]\n",
        "    customer_names = [faker_instance.company() + ' Pharmacy' for _ in range(num_customers)]\n",
        "    customer_locations = [faker_instance.city() for _ in range(num_customers)]\n",
        "\n",
        "    customers_df = pd.DataFrame({\n",
        "        'customer_id': customer_ids,\n",
        "        'customer_name': customer_names,\n",
        "        'customer_location': customer_locations\n",
        "    })\n",
        "    customers_df['customer_location'] = customers_df['customer_location'].astype('category')\n",
        "    return customers_df"
      ],
      "metadata": {
        "id": "KLz47K2ftXaY"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sales_df(num_sales_records: int, products_df: pd.DataFrame, customers_df: pd.DataFrame, warehouses_df: pd.DataFrame, start_date: datetime, end_date: datetime) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic sales data.\n",
        "\n",
        "    Args:\n",
        "        num_sales_records (int): The number of sales records to generate.\n",
        "        products_df (pd.DataFrame): DataFrame of product master data.\n",
        "        customers_df (pd.DataFrame): DataFrame of customer master data.\n",
        "        warehouses_df (pd.DataFrame): DataFrame of warehouse master data.\n",
        "        start_date (datetime): The start date for generating sales.\n",
        "        end_date (datetime): The end date for generating sales.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing sales_id, sales_date, customer_id, warehouse_id,\n",
        "                      product_id, sold_quantity, sales_price, and delivery_time_hours.\n",
        "    \"\"\"\n",
        "    sales_data = []\n",
        "    for i in range(num_sales_records):\n",
        "        sales_id = f'SALE_{i:06d}'\n",
        "        sales_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
        "\n",
        "        product = products_df.sample(1).iloc[0]\n",
        "        customer = customers_df.sample(1).iloc[0]\n",
        "        warehouse = warehouses_df.sample(1).iloc[0]\n",
        "\n",
        "        base_sold_quantity = np.random.randint(5, 100)\n",
        "        adjusted_sold_quantity = max(1, int(base_sold_quantity / (product['unit_price'] / 10 + 1)))\n",
        "\n",
        "        seasonal_factor = get_seasonal_factor(sales_date)\n",
        "        sold_quantity = max(1, int(adjusted_sold_quantity * seasonal_factor * np.random.uniform(0.8, 1.2)))\n",
        "\n",
        "        sales_price = product['unit_price'] * sold_quantity\n",
        "        delivery_time_hours = np.random.randint(4, 49)\n",
        "\n",
        "        sales_data.append({\n",
        "            'sales_id': sales_id,\n",
        "            'sales_date': sales_date,\n",
        "            'customer_id': customer['customer_id'],\n",
        "            'warehouse_id': warehouse['warehouse_id'],\n",
        "            'product_id': product['product_id'],\n",
        "            'sold_quantity': sold_quantity,\n",
        "            'sales_price': sales_price,\n",
        "            'delivery_time_hours': delivery_time_hours\n",
        "        })\n",
        "\n",
        "    sales_df = pd.DataFrame(sales_data)\n",
        "    sales_df['sales_date'] = pd.to_datetime(sales_df['sales_date'])\n",
        "    return sales_df\n"
      ],
      "metadata": {
        "id": "lHyLbsTItXdx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_returns_df(sales_df: pd.DataFrame, num_returns: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic product return data.\n",
        "\n",
        "    Args:\n",
        "        sales_df (pd.DataFrame): DataFrame of sales data.\n",
        "        num_returns (int): The number of return records to generate.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing return_id, sales_id, return_date, product_id,\n",
        "                      warehouse_id, returned_quantity, and return_reason.\n",
        "    \"\"\"\n",
        "    return_reasons = ['Damaged in transit', 'Incorrect item received', 'Customer changed mind', 'Expired product received']\n",
        "    returns_data = []\n",
        "\n",
        "    returned_sales = sales_df.sample(n=num_returns, replace=True).reset_index(drop=True) # Use replace=True if num_returns > len(sales_df)\n",
        "\n",
        "    for index, row in returned_sales.iterrows():\n",
        "        return_date = row['sales_date'] + timedelta(days=random.randint(1, 14))\n",
        "        returned_quantity = random.randint(1, row['sold_quantity'])\n",
        "        return_reason = random.choice(return_reasons)\n",
        "\n",
        "        returns_data.append({\n",
        "            'return_id': f'RET_{index:05d}',\n",
        "            'sales_id': row['sales_id'],\n",
        "            'return_date': return_date,\n",
        "            'product_id': row['product_id'],\n",
        "            'warehouse_id': row['warehouse_id'],\n",
        "            'returned_quantity': returned_quantity,\n",
        "            'return_reason': return_reason\n",
        "        })\n",
        "\n",
        "    returns_df = pd.DataFrame(returns_data)\n",
        "    returns_df['return_date'] = pd.to_datetime(returns_df['return_date'])\n",
        "    returns_df['return_reason'] = returns_df['return_reason'].astype('category')\n",
        "    return returns_df"
      ],
      "metadata": {
        "id": "LrAbnA3_xFC-"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_inventory_and_waste(\n",
        "    purchase_orders_df: pd.DataFrame,\n",
        "    sales_df: pd.DataFrame,\n",
        "    returns_df: pd.DataFrame,\n",
        "    products_df: pd.DataFrame,\n",
        "    warehouses_df: pd.DataFrame,\n",
        "    start_date: datetime,\n",
        "    end_date: datetime\n",
        ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Simulates inventory levels over time, tracking receipts, issues, returns, and spoilage.\n",
        "    Also generates records for stockouts and wasted inventory.\n",
        "\n",
        "    Args:\n",
        "        purchase_orders_df (pd.DataFrame): DataFrame of purchase orders.\n",
        "        sales_df (pd.DataFrame): DataFrame of sales data.\n",
        "        returns_df (pd.DataFrame): DataFrame of returns data.\n",
        "        products_df (pd.DataFrame): DataFrame of product master data.\n",
        "        warehouses_df (pd.DataFrame): DataFrame of warehouse master data.\n",
        "        start_date (datetime): The overall start date for the simulation.\n",
        "        end_date (datetime): The overall end date for the simulation.\n",
        "\n",
        "    Returns:\n",
        "        tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "            - inventory_df: DataFrame of inventory snapshots over time.\n",
        "            - waste_df: DataFrame of wasted (expired) inventory.\n",
        "            - stockout_df: DataFrame of stockout events.\n",
        "    \"\"\"\n",
        "    inventory_events = []\n",
        "\n",
        "    # Add Receipts from Purchase Orders\n",
        "    for _, row in purchase_orders_df.iterrows():\n",
        "        if row['delivery_status'] == 'Delivered':\n",
        "            expiry_date = row['actual_delivery_date'] + timedelta(days=int(products_df[products_df['product_id'] == row['product_id']]['avg_shelf_life_days'].iloc[0]))\n",
        "            inventory_events.append({\n",
        "                'event_date': row['actual_delivery_date'],\n",
        "                'product_id': row['product_id'],\n",
        "                'warehouse_id': random.choice(warehouses_df['warehouse_id'].tolist()),\n",
        "                'quantity_change': row['ordered_quantity'],\n",
        "                'event_type': 'Receipt',\n",
        "                'batch_number': f'BATCH_{row[\"po_id\"]}',\n",
        "                'expiry_date': expiry_date\n",
        "            })\n",
        "\n",
        "    # Add Issues from Sales\n",
        "    for _, row in sales_df.iterrows():\n",
        "        inventory_events.append({\n",
        "            'event_date': row['sales_date'],\n",
        "            'product_id': row['product_id'],\n",
        "            'warehouse_id': row['warehouse_id'],\n",
        "            'quantity_change': -row['sold_quantity'],\n",
        "            'event_type': 'Issue',\n",
        "            'batch_number': None, # Batch determined during simulation\n",
        "            'expiry_date': None # Expiry determined during simulation\n",
        "        })\n",
        "\n",
        "    # Add Receipts from Returns\n",
        "    for _, row in returns_df.iterrows():\n",
        "        returned_product_shelf_life = int(products_df[products_df['product_id'] == row['product_id']]['avg_shelf_life_days'].iloc[0])\n",
        "        expiry_date_return = row['return_date'] + timedelta(days=min(returned_product_shelf_life, 180))\n",
        "\n",
        "        inventory_events.append({\n",
        "            'event_date': row['return_date'],\n",
        "            'product_id': row['product_id'],\n",
        "            'warehouse_id': row['warehouse_id'],\n",
        "            'quantity_change': row['returned_quantity'],\n",
        "            'event_type': 'Return_Receipt',\n",
        "            'batch_number': f'RET_BATCH_{row[\"return_id\"]}',\n",
        "            'expiry_date': expiry_date_return\n",
        "        })\n",
        "\n",
        "    inventory_events_df = pd.DataFrame(inventory_events)\n",
        "    inventory_events_df['event_date'] = pd.to_datetime(inventory_events_df['event_date'])\n",
        "    inventory_events_df = inventory_events_df.sort_values(by='event_date').reset_index(drop=True)\n",
        "    inventory_events_df['event_type'] = inventory_events_df['event_type'].astype('category')\n",
        "\n",
        "\n",
        "    inventory_records = []\n",
        "    current_inventory = {} # Key: (warehouse_id, product_id, batch_number), Value: {'quantity': X, 'expiry_date': Y}\n",
        "    waste_records = []\n",
        "    stockout_records = []\n",
        "\n",
        "    all_dates = sorted(inventory_events_df['event_date'].unique())\n",
        "\n",
        "    for current_date_np in all_dates:\n",
        "        current_date = pd.to_datetime(current_date_np)\n",
        "\n",
        "        # --- Process Spoilage/Waste for the current date ---\n",
        "        expired_batches = []\n",
        "        for (wh_id, prod_id, batch_num), details in list(current_inventory.items()): # Use list() to iterate over a copy\n",
        "            if details['quantity'] > 0 and details['expiry_date'] and details['expiry_date'] <= current_date:\n",
        "                expired_batches.append(((wh_id, prod_id, batch_num), details['quantity']))\n",
        "\n",
        "        for (wh_id, prod_id, batch_num), expired_qty in expired_batches:\n",
        "            if current_inventory.get((wh_id, prod_id, batch_num), {}).get('quantity', 0) > 0:\n",
        "                wasted_amount = current_inventory[(wh_id, prod_id, batch_num)]['quantity']\n",
        "                waste_records.append({\n",
        "                    'waste_date': current_date,\n",
        "                    'warehouse_id': wh_id,\n",
        "                    'product_id': prod_id,\n",
        "                    'batch_number': batch_num,\n",
        "                    'wasted_quantity': wasted_amount,\n",
        "                    'reason': 'Expired'\n",
        "                })\n",
        "                current_inventory[(wh_id, prod_id, batch_num)]['quantity'] = 0\n",
        "\n",
        "        # --- Process daily events (Receipts, Issues, Returns) ---\n",
        "        daily_events = inventory_events_df[inventory_events_df['event_date'] == current_date].copy()\n",
        "\n",
        "        for _, event in daily_events.iterrows():\n",
        "            product_id = event['product_id']\n",
        "            warehouse_id = event['warehouse_id']\n",
        "            quantity_change = event['quantity_change']\n",
        "            event_type = event['event_type']\n",
        "\n",
        "            if event_type in ['Receipt', 'Return_Receipt']:\n",
        "                batch_number = event['batch_number']\n",
        "                expiry_date = event['expiry_date']\n",
        "                key = (warehouse_id, product_id, batch_number)\n",
        "                if key not in current_inventory:\n",
        "                    current_inventory[key] = {'quantity': 0, 'expiry_date': expiry_date}\n",
        "                current_inventory[key]['quantity'] += quantity_change\n",
        "            elif event_type == 'Issue':\n",
        "                remaining_to_sell = abs(quantity_change)\n",
        "\n",
        "                available_batches = []\n",
        "                for (wh_id, prod_id, batch_num), details in current_inventory.items():\n",
        "                    if wh_id == warehouse_id and prod_id == product_id and details['quantity'] > 0:\n",
        "                        available_batches.append((details['expiry_date'], batch_num, details['quantity']))\n",
        "\n",
        "                available_batches.sort() # Sort by expiry date (FEFO)\n",
        "\n",
        "                total_available_for_product = sum(current_inventory.get((wh_id, prod_id, b_num), {}).get('quantity', 0)\n",
        "                                                  for (wh_id, prod_id, b_num), _ in current_inventory.items()\n",
        "                                                  if wh_id == warehouse_id and prod_id == product_id)\n",
        "\n",
        "                if remaining_to_sell > total_available_for_product:\n",
        "                    stockout_quantity = remaining_to_sell - total_available_for_product\n",
        "                    stockout_records.append({\n",
        "                        'stockout_date': current_date,\n",
        "                        'warehouse_id': warehouse_id,\n",
        "                        'product_id': product_id,\n",
        "                        'stockout_quantity': stockout_quantity\n",
        "                    })\n",
        "                    remaining_to_sell = total_available_for_product # Only sell what's available\n",
        "\n",
        "                for expiry_date_batch, batch_num, batch_quantity in available_batches:\n",
        "                    key = (warehouse_id, product_id, batch_num)\n",
        "                    if remaining_to_sell <= 0:\n",
        "                        break\n",
        "\n",
        "                    if current_inventory[key]['quantity'] >= remaining_to_sell:\n",
        "                        current_inventory[key]['quantity'] -= remaining_to_sell\n",
        "                        remaining_to_sell = 0\n",
        "                    else:\n",
        "                        remaining_to_sell -= current_inventory[key]['quantity']\n",
        "                        current_inventory[key]['quantity'] = 0\n",
        "\n",
        "        # Record current inventory state for this date\n",
        "        for (wh_id, prod_id, batch_num), details in current_inventory.items():\n",
        "            if details['quantity'] > 0:\n",
        "                inventory_records.append({\n",
        "                    'snapshot_date': current_date,\n",
        "                    'warehouse_id': wh_id,\n",
        "                    'product_id': prod_id,\n",
        "                    'batch_number': batch_num,\n",
        "                    'quantity_on_hand': details['quantity'],\n",
        "                    'expiry_date': details['expiry_date']\n",
        "                })\n",
        "\n",
        "    inventory_df = pd.DataFrame(inventory_records)\n",
        "    inventory_df['snapshot_date'] = pd.to_datetime(inventory_df['snapshot_date'])\n",
        "    inventory_df['expiry_date'] = pd.to_datetime(inventory_df['expiry_date'])\n",
        "    inventory_df = inventory_df.sort_values(by=['snapshot_date', 'warehouse_id', 'product_id', 'expiry_date']).reset_index(drop=True)\n",
        "    inventory_df = inventory_df.drop_duplicates(subset=['snapshot_date', 'warehouse_id', 'product_id', 'batch_number'], keep='last')\n",
        "\n",
        "    waste_df = pd.DataFrame(waste_records)\n",
        "    if not waste_df.empty:\n",
        "        waste_df['waste_date'] = pd.to_datetime(waste_df['waste_date'])\n",
        "        waste_df['reason'] = waste_df['reason'].astype('category')\n",
        "\n",
        "    stockout_df = pd.DataFrame(stockout_records)\n",
        "    if not stockout_df.empty:\n",
        "        stockout_df['stockout_date'] = pd.to_datetime(stockout_df['stockout_date'])\n",
        "\n",
        "    return inventory_df, waste_df, stockout_df"
      ],
      "metadata": {
        "id": "ZnK5TwcaxFGS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    NUM_PRODUCTS = 5000\n",
        "    NUM_WAREHOUSES = 10\n",
        "    NUM_SUPPLIERS = 50\n",
        "    NUM_CUSTOMERS = 1000\n",
        "    NUM_PURCHASE_ORDERS = 10000\n",
        "    NUM_SALES_RECORDS = 50000\n",
        "    NUM_RETURNS = int(NUM_SALES_RECORDS * 0.05) # 5% of sales are returned\n",
        "\n",
        "    START_DATE = datetime.now() - timedelta(days=2*365)\n",
        "    END_DATE = datetime.now()\n",
        "\n",
        "\n",
        "    products_df = generate_products_df(NUM_PRODUCTS, fake)\n",
        "    print(\"products_df\")\n",
        "    print(products_df.head())\n",
        "\n",
        "    warehouses_df = generate_warehouses_df(NUM_WAREHOUSES)\n",
        "    print(\"\\nwarehouses_df\")\n",
        "    print(warehouses_df.head())\n",
        "\n",
        "    suppliers_df = generate_suppliers_df(NUM_SUPPLIERS, fake)\n",
        "    print(\"\\nsuppliers_df\")\n",
        "    print(suppliers_df.head())\n",
        "\n",
        "    purchase_orders_df = generate_purchase_orders_df(NUM_PURCHASE_ORDERS, products_df, suppliers_df, START_DATE, END_DATE)\n",
        "    print(\"\\npurchase_orders_df\")\n",
        "    print(purchase_orders_df.head())\n",
        "\n",
        "    customers_df = generate_customers_df(NUM_CUSTOMERS, fake)\n",
        "    print(\"\\ncustomers_df\")\n",
        "    print(customers_df.head())\n",
        "\n",
        "    sales_df = generate_sales_df(NUM_SALES_RECORDS, products_df, customers_df, warehouses_df, START_DATE, END_DATE)\n",
        "    print(\"\\nsales_df\")\n",
        "    print(sales_df.head())\n",
        "\n",
        "    returns_df = generate_returns_df(sales_df, NUM_RETURNS)\n",
        "    print(\"\\nreturns_df\")\n",
        "    print(returns_df.head())\n",
        "\n",
        "    inventory_df, waste_df, stockout_df = simulate_inventory_and_waste(purchase_orders_df, sales_df, returns_df, products_df, warehouses_df, START_DATE, END_DATE)\n",
        "    print(\"\\ninventory_df\")\n",
        "    print(inventory_df.head())\n",
        "\n",
        "    if not waste_df.empty:\n",
        "        print(\"\\nwaste_df (Spoilage)\")\n",
        "        print(waste_df.head())\n",
        "    else:\n",
        "        print(\"\\nNo Waste (Spoilage) records generated.\")\n",
        "\n",
        "    if not stockout_df.empty:\n",
        "        print(\"\\nstockout_df\")\n",
        "        print(stockout_df.head())\n",
        "    else:\n",
        "        print(\"\\nNo Stockout records generated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoKhxZEixFJL",
        "outputId": "5d5593e9-fffd-4167-f762-305518431509"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "products_df\n",
            "   product_id                product_name   product_category  unit_price  \\\n",
            "0  PROD_00001      Capsule player account   Gastrointestinal       20.82   \n",
            "1  PROD_00002  Ointment energy technology     Pain Relievers       14.39   \n",
            "2  PROD_00003          MP-857 unit player    Herbal Remedies       16.28   \n",
            "3  PROD_00004      Capsule reduce medical           Hormonal       37.71   \n",
            "4  PROD_00005         Drop senior mention  Ophthalmic & Otic       23.17   \n",
            "\n",
            "   avg_shelf_life_days storage_conditions  \n",
            "0                  730       Cold Storage  \n",
            "1                  730   Room Temperature  \n",
            "2                 1095       Cold Storage  \n",
            "3                  730   Room Temperature  \n",
            "4                 1460   Room Temperature  \n",
            "\n",
            "warehouses_df\n",
            "  warehouse_id             warehouse_name warehouse_city  latitude  longitude  \\\n",
            "0        WH_01   Central Warehouse Tehran         Tehran   35.6892    51.3890   \n",
            "1        WH_02  Central Warehouse Mashhad        Mashhad   36.2605    59.6168   \n",
            "2        WH_03  Central Warehouse Isfahan        Isfahan   32.6546    51.6670   \n",
            "3        WH_04   Central Warehouse Tabriz         Tabriz   38.0805    46.2918   \n",
            "4        WH_05   Central Warehouse Shiraz         Shiraz   29.6065    52.5414   \n",
            "\n",
            "   capacity_units  \n",
            "0         6988115  \n",
            "1         4198010  \n",
            "2         1402880  \n",
            "3         1357361  \n",
            "4         1127960  \n",
            "\n",
            "suppliers_df\n",
            "  supplier_id                 supplier_name supplier_location  \\\n",
            "0     SUP_001  Spence, Mcfarland and Jordan      Williammouth   \n",
            "1     SUP_002        Garcia, Owen and Yates   West Jamesshire   \n",
            "2     SUP_003                    Roth-Stout      Elliotthaven   \n",
            "3     SUP_004                   Salinas PLC        West Jimmy   \n",
            "4     SUP_005              Fernandez-Turner        West Dylan   \n",
            "\n",
            "   avg_lead_time_days  reliability_score  \n",
            "0                  27               0.95  \n",
            "1                  27               0.81  \n",
            "2                   7               0.80  \n",
            "3                  25               0.93  \n",
            "4                  25               0.99  \n",
            "\n",
            "purchase_orders_df\n",
            "      po_id                    po_date supplier_id  product_id  \\\n",
            "0  PO_00000 2024-09-24 10:03:39.585321     SUP_005  PROD_00531   \n",
            "1  PO_00001 2023-10-19 10:03:39.585321     SUP_026  PROD_03393   \n",
            "2  PO_00002 2023-09-27 10:03:39.585321     SUP_042  PROD_04426   \n",
            "3  PO_00003 2025-03-29 10:03:39.585321     SUP_018  PROD_04337   \n",
            "4  PO_00004 2023-10-29 10:03:39.585321     SUP_004  PROD_01797   \n",
            "\n",
            "   ordered_quantity  unit_cost     expected_delivery_date  \\\n",
            "0              1393  15.164621 2024-10-19 10:03:39.585321   \n",
            "1              1328   4.466697 2023-11-14 10:03:39.585321   \n",
            "2              2359   4.889884 2023-10-03 10:03:39.585321   \n",
            "3              1385   6.218909 2025-04-10 10:03:39.585321   \n",
            "4               262  11.696603 2023-11-23 10:03:39.585321   \n",
            "\n",
            "        actual_delivery_date delivery_status  \n",
            "0 2024-10-19 10:03:39.585321       Delivered  \n",
            "1 2023-11-14 10:03:39.585321       Delivered  \n",
            "2 2023-10-03 10:03:39.585321       Delivered  \n",
            "3 2025-04-10 10:03:39.585321       Delivered  \n",
            "4 2023-11-23 10:03:39.585321       Delivered  \n",
            "\n",
            "customers_df\n",
            "  customer_id                           customer_name    customer_location\n",
            "0   CUST_0001                     Taylor Inc Pharmacy   North Richardhaven\n",
            "1   CUST_0002                       Hall PLC Pharmacy  North Aliciaborough\n",
            "2   CUST_0003                 Cisneros-Stone Pharmacy           Benderstad\n",
            "3   CUST_0004  Mullins, Robertson and Thomas Pharmacy             Karastad\n",
            "4   CUST_0005             Hernandez-Castillo Pharmacy     Port Brendamouth\n",
            "\n",
            "sales_df\n",
            "      sales_id                 sales_date customer_id warehouse_id  \\\n",
            "0  SALE_000000 2024-07-02 10:03:39.585321   CUST_0218        WH_04   \n",
            "1  SALE_000001 2025-07-04 10:03:39.585321   CUST_0134        WH_09   \n",
            "2  SALE_000002 2023-08-16 10:03:39.585321   CUST_0161        WH_02   \n",
            "3  SALE_000003 2024-03-17 10:03:39.585321   CUST_0105        WH_05   \n",
            "4  SALE_000004 2024-03-16 10:03:39.585321   CUST_0774        WH_04   \n",
            "\n",
            "   product_id  sold_quantity  sales_price  delivery_time_hours  \n",
            "0  PROD_04385             29       344.81                   42  \n",
            "1  PROD_04446              7       217.63                    6  \n",
            "2  PROD_00174             15       235.95                   10  \n",
            "3  PROD_02292              7       297.15                   47  \n",
            "4  PROD_03516             51       450.33                   13  \n",
            "\n",
            "returns_df\n",
            "   return_id     sales_id                return_date  product_id warehouse_id  \\\n",
            "0  RET_00000  SALE_024077 2023-10-30 10:03:39.585321  PROD_01890        WH_02   \n",
            "1  RET_00001  SALE_018248 2024-06-27 10:03:39.585321  PROD_01159        WH_04   \n",
            "2  RET_00002  SALE_035966 2025-03-18 10:03:39.585321  PROD_01262        WH_06   \n",
            "3  RET_00003  SALE_031615 2025-04-14 10:03:39.585321  PROD_02267        WH_05   \n",
            "4  RET_00004  SALE_030617 2023-11-24 10:03:39.585321  PROD_02933        WH_02   \n",
            "\n",
            "   returned_quantity             return_reason  \n",
            "0                  3     Customer changed mind  \n",
            "1                  9        Damaged in transit  \n",
            "2                  8   Incorrect item received  \n",
            "3                  3  Expired product received  \n",
            "4                  4  Expired product received  \n",
            "\n",
            "inventory_df\n",
            "               snapshot_date warehouse_id  product_id         batch_number  \\\n",
            "0 2023-08-04 10:03:39.585321        WH_03  PROD_01023  RET_BATCH_RET_02223   \n",
            "1 2023-08-04 10:03:39.585321        WH_03  PROD_01087  RET_BATCH_RET_01601   \n",
            "2 2023-08-05 10:03:39.585321        WH_03  PROD_01023  RET_BATCH_RET_02223   \n",
            "3 2023-08-05 10:03:39.585321        WH_03  PROD_01087  RET_BATCH_RET_01601   \n",
            "4 2023-08-05 10:03:39.585321        WH_08  PROD_02403  RET_BATCH_RET_01680   \n",
            "\n",
            "   quantity_on_hand                expiry_date  \n",
            "0                 4 2024-01-31 10:03:39.585321  \n",
            "1                 1 2024-01-31 10:03:39.585321  \n",
            "2                 4 2024-01-31 10:03:39.585321  \n",
            "3                 1 2024-01-31 10:03:39.585321  \n",
            "4                 1 2024-02-01 10:03:39.585321  \n",
            "\n",
            "waste_df (Spoilage)\n",
            "                  waste_date warehouse_id  product_id         batch_number  \\\n",
            "0 2024-01-31 10:03:39.585321        WH_03  PROD_01023  RET_BATCH_RET_02223   \n",
            "1 2024-02-01 10:03:39.585321        WH_08  PROD_02403  RET_BATCH_RET_01680   \n",
            "2 2024-02-02 10:03:39.585321        WH_08  PROD_04345  RET_BATCH_RET_01756   \n",
            "3 2024-02-02 10:03:39.585321        WH_06  PROD_04007  RET_BATCH_RET_00277   \n",
            "4 2024-02-02 10:03:39.585321        WH_08  PROD_00343  RET_BATCH_RET_01893   \n",
            "\n",
            "   wasted_quantity   reason  \n",
            "0                4  Expired  \n",
            "1                1  Expired  \n",
            "2                4  Expired  \n",
            "3                4  Expired  \n",
            "4               11  Expired  \n",
            "\n",
            "stockout_df\n",
            "               stockout_date warehouse_id  product_id  stockout_quantity\n",
            "0 2023-07-31 10:03:39.585321        WH_01  PROD_01077                  7\n",
            "1 2023-07-31 10:03:39.585321        WH_05  PROD_03697                 14\n",
            "2 2023-07-31 10:03:39.585321        WH_04  PROD_04635                 22\n",
            "3 2023-07-31 10:03:39.585321        WH_03  PROD_02838                 11\n",
            "4 2023-07-31 10:03:39.585321        WH_03  PROD_00764                  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV (for easy viewing)\n",
        "    products_df.to_csv('products.csv', index=False)\n",
        "    warehouses_df.to_csv('warehouses.csv', index=False)\n",
        "    suppliers_df.to_csv('suppliers.csv', index=False)\n",
        "    customers_df.to_csv('customers.csv', index=False)\n",
        "    purchase_orders_df.to_csv('purchase_orders.csv', index=False)\n",
        "    sales_df.to_csv('sales.csv', index=False)\n",
        "    returns_df.to_csv('returns.csv', index=False)\n",
        "    inventory_df.to_csv('inventory.csv', index=False)\n",
        "    waste_df.to_csv('waste.csv', index=False)\n",
        "    stockout_df.to_csv('stockouts.csv', index=False)\n",
        "\n",
        "\n",
        "    products_df.to_parquet('products.parquet', index=False)\n",
        "    warehouses_df.to_parquet('warehouses.parquet', index=False)\n",
        "    suppliers_df.to_parquet('suppliers.parquet', index=False)\n",
        "    customers_df.to_parquet('customers.parquet', index=False)\n",
        "    purchase_orders_df.to_parquet('purchase_orders.parquet', index=False)\n",
        "    sales_df.to_parquet('sales.parquet', index=False)\n",
        "    returns_df.to_parquet('returns.parquet', index=False)\n",
        "    inventory_df.to_parquet('inventory.parquet', index=False)\n",
        "    waste_df.to_parquet('waste.parquet', index=False)\n",
        "    stockout_df.to_parquet('stockouts.parquet', index=False)"
      ],
      "metadata": {
        "id": "VIjpSE40xFLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxlr5KGttXjZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}