{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8nB0jP63grdCcm+NIfG9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZahraKheyrandish/Supply-Chain-Optimization-Inventory-Analysis/blob/main/01_data_generation.ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiQcajlatW-s",
        "outputId": "e83cdf96-bcad-4782-8e01-9d4f27466333"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Faker in /usr/local/lib/python3.11/dist-packages (37.4.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from Faker) (2025.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "0iauelW6tXCB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake = Faker('en_US')\n",
        "Faker.seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "metadata": {
        "id": "TWdIgDeItXEI"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_seasonal_factor(date: datetime) -> float:\n",
        "    \"\"\"\n",
        "    Calculates a seasonal factor based on the month.\n",
        "    Boosts sales in winter months, slightly dips in summer.\n",
        "\n",
        "    Args:\n",
        "        date (datetime): The date for which to calculate the seasonal factor.\n",
        "\n",
        "    Returns:\n",
        "        float: The seasonal factor.\n",
        "    \"\"\"\n",
        "    month = date.month\n",
        "    if month in [12, 1, 2]:\n",
        "        return 1.5\n",
        "    elif month in [7, 8]:\n",
        "        return 0.8\n",
        "    return 1.0\n"
      ],
      "metadata": {
        "id": "mJfgRXCRtXLk"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_products_df(num_products: int, faker_instance: Faker) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic product data for a pharmaceutical company.\n",
        "\n",
        "    Args:\n",
        "        num_products (int): The number of unique products to generate.\n",
        "        faker_instance (Faker): An instance of the Faker library for generating names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing product_id, product_name, product_category,\n",
        "                      unit_price, avg_shelf_life_days, and storage_conditions.\n",
        "    \"\"\"\n",
        "    product_ids = [f'PROD_{i:05d}' for i in range(1, num_products + 1)]\n",
        "    product_categories = [\n",
        "        'Antibiotics', 'Pain Relievers', 'Anti-Inflammatories', 'Vitamins & Supplements',\n",
        "        'Cardiovascular', 'Gastrointestinal', 'Respiratory', 'Neurological',\n",
        "        'Dermatological', 'Ophthalmic & Otic', 'Diabetic Care', 'Hormonal',\n",
        "        'Herbal Remedies', 'Disposable Medical Devices'\n",
        "    ]\n",
        "    product_names = []\n",
        "    for _ in range(num_products):\n",
        "        if random.random() < 0.7:\n",
        "            product_names.append(f'{random.choice([\"Tablet\", \"Capsule\", \"Syrup\", \"Ointment\", \"Ampoule\", \"Drop\", \"Cream\"])} {faker_instance.word()} {faker_instance.word()}')\n",
        "        else:\n",
        "            product_names.append(f'{\"\".join(random.choices(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", k=2))}-{random.randint(100,999)} {random.choice([\"mg\", \"g\", \"ml\", \"unit\"])} {faker_instance.word()}')\n",
        "\n",
        "    unit_prices = np.round(np.random.lognormal(mean=np.log(20), sigma=0.8, size=num_products), 2)\n",
        "    unit_prices = np.maximum(unit_prices, 1.00)\n",
        "    shelf_life_days = np.random.choice([365, 730, 1095, 1460, 1825], size=num_products, p=[0.1, 0.4, 0.3, 0.1, 0.1])\n",
        "    storage_conditions = np.random.choice(['Room Temperature', 'Cold Storage', 'Protect from Light/Moisture', 'Refrigerated (2-8Â°C)'], size=num_products, p=[0.6, 0.2, 0.1, 0.1])\n",
        "\n",
        "    products_df = pd.DataFrame({\n",
        "        'product_id': product_ids,\n",
        "        'product_name': product_names,\n",
        "        'product_category': np.random.choice(product_categories, size=num_products),\n",
        "        'unit_price': unit_prices,\n",
        "        'avg_shelf_life_days': shelf_life_days,\n",
        "        'storage_conditions': storage_conditions\n",
        "    })\n",
        "    products_df['product_category'] = products_df['product_category'].astype('category')\n",
        "    products_df['storage_conditions'] = products_df['storage_conditions'].astype('category')\n",
        "    return products_df"
      ],
      "metadata": {
        "id": "GwwuukSAtXOB"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_warehouses_df(num_warehouses: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic warehouse data.\n",
        "\n",
        "    Args:\n",
        "        num_warehouses (int): The number of warehouses to generate.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing warehouse_id, warehouse_name, warehouse_city,\n",
        "                      latitude, longitude, and capacity_units.\n",
        "    \"\"\"\n",
        "    warehouse_ids = [f'WH_{i:02d}' for i in range(1, num_warehouses + 1)]\n",
        "    warehouse_locations = {\n",
        "        'Tehran': {'lat': 35.6892, 'lon': 51.3890}, 'Mashhad': {'lat': 36.2605, 'lon': 59.6168},\n",
        "        'Isfahan': {'lat': 32.6546, 'lon': 51.6670}, 'Tabriz': {'lat': 38.0805, 'lon': 46.2918},\n",
        "        'Shiraz': {'lat': 29.6065, 'lon': 52.5414}, 'Ahvaz': {'lat': 31.3204, 'lon': 48.6720},\n",
        "        'Karaj': {'lat': 35.8322, 'lon': 50.9667}, 'Rasht': {'lat': 37.2752, 'lon': 49.5891},\n",
        "        'Kerman': {'lat': 30.2832, 'lon': 57.0671}, 'Bandar Abbas': {'lat': 27.1887, 'lon': 56.2829}\n",
        "    }\n",
        "    warehouse_names = [f'Central Warehouse {city}' for city in warehouse_locations.keys()]\n",
        "    warehouse_latitudes = [loc['lat'] for loc in warehouse_locations.values()]\n",
        "    warehouse_longitudes = [loc['lon'] for loc in warehouse_locations.values()]\n",
        "    capacity_units = np.random.randint(1_000_000, 5_000_000, size=num_warehouses)\n",
        "    capacity_units[0] = np.random.randint(4_000_000, 7_000_000)\n",
        "\n",
        "    warehouses_df = pd.DataFrame({\n",
        "        'warehouse_id': warehouse_ids,\n",
        "        'warehouse_name': warehouse_names,\n",
        "        'warehouse_city': list(warehouse_locations.keys()),\n",
        "        'latitude': warehouse_latitudes,\n",
        "        'longitude': warehouse_longitudes,\n",
        "        'capacity_units': capacity_units\n",
        "    })\n",
        "    warehouses_df['warehouse_city'] = warehouses_df['warehouse_city'].astype('category')\n",
        "    return warehouses_df"
      ],
      "metadata": {
        "id": "2DgLCaImtXTE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_suppliers_df(num_suppliers: int, faker_instance: Faker) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic supplier data.\n",
        "\n",
        "    Args:\n",
        "        num_suppliers (int): The number of suppliers to generate.\n",
        "        faker_instance (Faker): An instance of the Faker library for generating names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing supplier_id, supplier_name, supplier_location,\n",
        "                      avg_lead_time_days, and reliability_score.\n",
        "    \"\"\"\n",
        "    supplier_ids = [f'SUP_{i:03d}' for i in range(1, num_suppliers + 1)]\n",
        "    supplier_names = [faker_instance.company() for _ in range(num_suppliers)]\n",
        "    supplier_locations = [faker_instance.city() for _ in range(num_suppliers)]\n",
        "    avg_lead_time_days = np.random.randint(5, 30, size=num_suppliers)\n",
        "    reliability_scores = np.round(np.random.uniform(0.7, 0.99, size=num_suppliers), 2)\n",
        "\n",
        "    suppliers_df = pd.DataFrame({\n",
        "        'supplier_id': supplier_ids,\n",
        "        'supplier_name': supplier_names,\n",
        "        'supplier_location': supplier_locations,\n",
        "        'avg_lead_time_days': avg_lead_time_days,\n",
        "        'reliability_score': reliability_scores\n",
        "    })\n",
        "    suppliers_df['supplier_location'] = suppliers_df['supplier_location'].astype('category')\n",
        "    return suppliers_df"
      ],
      "metadata": {
        "id": "LuOk_tcotXVU"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_purchase_orders_df(num_purchase_orders: int, products_df: pd.DataFrame, suppliers_df: pd.DataFrame, start_date: datetime, end_date: datetime) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic purchase order data.\n",
        "\n",
        "    Args:\n",
        "        num_purchase_orders (int): The number of purchase orders to generate.\n",
        "        products_df (pd.DataFrame): DataFrame of product master data.\n",
        "        suppliers_df (pd.DataFrame): DataFrame of supplier master data.\n",
        "        start_date (datetime): The start date for generating POs.\n",
        "        end_date (datetime): The end date for generating POs.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing po_id, po_date, supplier_id, product_id,\n",
        "                      ordered_quantity, unit_cost, expected_delivery_date, actual_delivery_date,\n",
        "                      and delivery_status.\n",
        "    \"\"\"\n",
        "    po_data = []\n",
        "    for i in range(num_purchase_orders):\n",
        "        po_id = f'PO_{i:05d}'\n",
        "        po_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
        "\n",
        "        product = products_df.sample(1).iloc[0]\n",
        "        supplier = suppliers_df.sample(1, weights='reliability_score').iloc[0]\n",
        "\n",
        "        base_quantity = np.random.randint(500, 5000)\n",
        "        ordered_quantity = max(10, int(base_quantity / (product['unit_price'] / 10 + 1)))\n",
        "        unit_cost = product['unit_price'] * np.random.uniform(0.5, 0.8)\n",
        "        expected_delivery_date = po_date + timedelta(days=int(supplier['avg_lead_time_days']))\n",
        "\n",
        "        delivery_delay_days = 0\n",
        "        if random.random() < (1 - supplier['reliability_score']):\n",
        "            delivery_delay_days = np.random.randint(1, 10)\n",
        "            if random.random() < 0.2:\n",
        "                delivery_delay_days = np.random.randint(10, 30)\n",
        "\n",
        "        actual_delivery_date = expected_delivery_date + timedelta(days=int(delivery_delay_days))\n",
        "\n",
        "        delivery_status = 'Delivered'\n",
        "        if actual_delivery_date > end_date:\n",
        "            delivery_status = 'Pending'\n",
        "        elif actual_delivery_date > expected_delivery_date:\n",
        "            delivery_status = 'Delayed'\n",
        "\n",
        "        po_data.append({\n",
        "            'po_id': po_id,\n",
        "            'po_date': po_date,\n",
        "            'supplier_id': supplier['supplier_id'],\n",
        "            'product_id': product['product_id'],\n",
        "            'ordered_quantity': ordered_quantity,\n",
        "            'unit_cost': unit_cost,\n",
        "            'expected_delivery_date': expected_delivery_date,\n",
        "            'actual_delivery_date': actual_delivery_date,\n",
        "            'delivery_status': delivery_status\n",
        "        })\n",
        "\n",
        "    purchase_orders_df = pd.DataFrame(po_data)\n",
        "    purchase_orders_df['po_date'] = pd.to_datetime(purchase_orders_df['po_date'])\n",
        "    purchase_orders_df['expected_delivery_date'] = pd.to_datetime(purchase_orders_df['expected_delivery_date'])\n",
        "    purchase_orders_df['actual_delivery_date'] = pd.to_datetime(purchase_orders_df['actual_delivery_date'])\n",
        "    purchase_orders_df['delivery_status'] = purchase_orders_df['delivery_status'].astype('category')\n",
        "    return purchase_orders_df\n",
        "\n"
      ],
      "metadata": {
        "id": "X8EQAYKjtXX6"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_customers_df(num_customers: int, faker_instance: Faker) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic customer (pharmacy) data.\n",
        "\n",
        "    Args:\n",
        "        num_customers (int): The number of customers to generate.\n",
        "        faker_instance (Faker): An instance of the Faker library for generating names.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing customer_id, customer_name, and customer_location.\n",
        "    \"\"\"\n",
        "    customer_ids = [f'CUST_{i:04d}' for i in range(1, num_customers + 1)]\n",
        "    customer_names = [faker_instance.company() + ' Pharmacy' for _ in range(num_customers)]\n",
        "    customer_locations = [faker_instance.city() for _ in range(num_customers)]\n",
        "\n",
        "    customers_df = pd.DataFrame({\n",
        "        'customer_id': customer_ids,\n",
        "        'customer_name': customer_names,\n",
        "        'customer_location': customer_locations\n",
        "    })\n",
        "    customers_df['customer_location'] = customers_df['customer_location'].astype('category')\n",
        "    return customers_df"
      ],
      "metadata": {
        "id": "KLz47K2ftXaY"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sales_df(num_sales_records: int, products_df: pd.DataFrame, customers_df: pd.DataFrame, warehouses_df: pd.DataFrame, start_date: datetime, end_date: datetime) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic sales data.\n",
        "\n",
        "    Args:\n",
        "        num_sales_records (int): The number of sales records to generate.\n",
        "        products_df (pd.DataFrame): DataFrame of product master data.\n",
        "        customers_df (pd.DataFrame): DataFrame of customer master data.\n",
        "        warehouses_df (pd.DataFrame): DataFrame of warehouse master data.\n",
        "        start_date (datetime): The start date for generating sales.\n",
        "        end_date (datetime): The end date for generating sales.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing sales_id, sales_date, customer_id, warehouse_id,\n",
        "                      product_id, sold_quantity, sales_price, and delivery_time_hours.\n",
        "    \"\"\"\n",
        "    sales_data = []\n",
        "    for i in range(num_sales_records):\n",
        "        sales_id = f'SALE_{i:06d}'\n",
        "        sales_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
        "\n",
        "        product = products_df.sample(1).iloc[0]\n",
        "        customer = customers_df.sample(1).iloc[0]\n",
        "        warehouse = warehouses_df.sample(1).iloc[0]\n",
        "\n",
        "        base_sold_quantity = np.random.randint(5, 100)\n",
        "        adjusted_sold_quantity = max(1, int(base_sold_quantity / (product['unit_price'] / 10 + 1)))\n",
        "\n",
        "        seasonal_factor = get_seasonal_factor(sales_date)\n",
        "        sold_quantity = max(1, int(adjusted_sold_quantity * seasonal_factor * np.random.uniform(0.8, 1.2)))\n",
        "\n",
        "        sales_price = product['unit_price'] * sold_quantity\n",
        "        delivery_time_hours = np.random.randint(4, 49)\n",
        "\n",
        "        sales_data.append({\n",
        "            'sales_id': sales_id,\n",
        "            'sales_date': sales_date,\n",
        "            'customer_id': customer['customer_id'],\n",
        "            'warehouse_id': warehouse['warehouse_id'],\n",
        "            'product_id': product['product_id'],\n",
        "            'sold_quantity': sold_quantity,\n",
        "            'sales_price': sales_price,\n",
        "            'delivery_time_hours': delivery_time_hours\n",
        "        })\n",
        "\n",
        "    sales_df = pd.DataFrame(sales_data)\n",
        "    sales_df['sales_date'] = pd.to_datetime(sales_df['sales_date'])\n",
        "    return sales_df\n"
      ],
      "metadata": {
        "id": "lHyLbsTItXdx"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_returns_df(sales_df: pd.DataFrame, num_returns: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a DataFrame of synthetic product return data.\n",
        "\n",
        "    Args:\n",
        "        sales_df (pd.DataFrame): DataFrame of sales data.\n",
        "        num_returns (int): The number of return records to generate.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing return_id, sales_id, return_date, product_id,\n",
        "                      warehouse_id, returned_quantity, and return_reason.\n",
        "    \"\"\"\n",
        "    return_reasons = ['Damaged in transit', 'Incorrect item received', 'Customer changed mind', 'Expired product received']\n",
        "    returns_data = []\n",
        "\n",
        "    returned_sales = sales_df.sample(n=num_returns, replace=True).reset_index(drop=True) # Use replace=True if num_returns > len(sales_df)\n",
        "\n",
        "    for index, row in returned_sales.iterrows():\n",
        "        return_date = row['sales_date'] + timedelta(days=random.randint(1, 14))\n",
        "        returned_quantity = random.randint(1, row['sold_quantity'])\n",
        "        return_reason = random.choice(return_reasons)\n",
        "\n",
        "        returns_data.append({\n",
        "            'return_id': f'RET_{index:05d}',\n",
        "            'sales_id': row['sales_id'],\n",
        "            'return_date': return_date,\n",
        "            'product_id': row['product_id'],\n",
        "            'warehouse_id': row['warehouse_id'],\n",
        "            'returned_quantity': returned_quantity,\n",
        "            'return_reason': return_reason\n",
        "        })\n",
        "\n",
        "    returns_df = pd.DataFrame(returns_data)\n",
        "    returns_df['return_date'] = pd.to_datetime(returns_df['return_date'])\n",
        "    returns_df['return_reason'] = returns_df['return_reason'].astype('category')\n",
        "    return returns_df"
      ],
      "metadata": {
        "id": "LrAbnA3_xFC-"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_inventory_and_waste(\n",
        "    purchase_orders_df: pd.DataFrame,\n",
        "    sales_df: pd.DataFrame,\n",
        "    returns_df: pd.DataFrame,\n",
        "    products_df: pd.DataFrame,\n",
        "    warehouses_df: pd.DataFrame,\n",
        "    start_date: datetime,\n",
        "    end_date: datetime\n",
        ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Simulates inventory levels over time, tracking receipts, issues, returns, and spoilage.\n",
        "    Also generates records for stockouts and wasted inventory.\n",
        "\n",
        "    Args:\n",
        "        purchase_orders_df (pd.DataFrame): DataFrame of purchase orders.\n",
        "        sales_df (pd.DataFrame): DataFrame of sales data.\n",
        "        returns_df (pd.DataFrame): DataFrame of returns data.\n",
        "        products_df (pd.DataFrame): DataFrame of product master data.\n",
        "        warehouses_df (pd.DataFrame): DataFrame of warehouse master data.\n",
        "        start_date (datetime): The overall start date for the simulation.\n",
        "        end_date (datetime): The overall end date for the simulation.\n",
        "\n",
        "    Returns:\n",
        "        tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "            - inventory_df: DataFrame of inventory snapshots over time.\n",
        "            - waste_df: DataFrame of wasted (expired) inventory.\n",
        "            - stockout_df: DataFrame of stockout events.\n",
        "    \"\"\"\n",
        "    inventory_events = []\n",
        "\n",
        "    # Add Receipts from Purchase Orders\n",
        "    for _, row in purchase_orders_df.iterrows():\n",
        "        if row['delivery_status'] == 'Delivered':\n",
        "            expiry_date = row['actual_delivery_date'] + timedelta(days=int(products_df[products_df['product_id'] == row['product_id']]['avg_shelf_life_days'].iloc[0]))\n",
        "            inventory_events.append({\n",
        "                'event_date': row['actual_delivery_date'],\n",
        "                'product_id': row['product_id'],\n",
        "                'warehouse_id': random.choice(warehouses_df['warehouse_id'].tolist()),\n",
        "                'quantity_change': row['ordered_quantity'],\n",
        "                'event_type': 'Receipt',\n",
        "                'batch_number': f'BATCH_{row[\"po_id\"]}',\n",
        "                'expiry_date': expiry_date\n",
        "            })\n",
        "\n",
        "    # Add Issues from Sales\n",
        "    for _, row in sales_df.iterrows():\n",
        "        inventory_events.append({\n",
        "            'event_date': row['sales_date'],\n",
        "            'product_id': row['product_id'],\n",
        "            'warehouse_id': row['warehouse_id'],\n",
        "            'quantity_change': -row['sold_quantity'],\n",
        "            'event_type': 'Issue',\n",
        "            'batch_number': None, # Batch determined during simulation\n",
        "            'expiry_date': None # Expiry determined during simulation\n",
        "        })\n",
        "\n",
        "    # Add Receipts from Returns\n",
        "    for _, row in returns_df.iterrows():\n",
        "        returned_product_shelf_life = int(products_df[products_df['product_id'] == row['product_id']]['avg_shelf_life_days'].iloc[0])\n",
        "        expiry_date_return = row['return_date'] + timedelta(days=min(returned_product_shelf_life, 180))\n",
        "\n",
        "        inventory_events.append({\n",
        "            'event_date': row['return_date'],\n",
        "            'product_id': row['product_id'],\n",
        "            'warehouse_id': row['warehouse_id'],\n",
        "            'quantity_change': row['returned_quantity'],\n",
        "            'event_type': 'Return_Receipt',\n",
        "            'batch_number': f'RET_BATCH_{row[\"return_id\"]}',\n",
        "            'expiry_date': expiry_date_return\n",
        "        })\n",
        "\n",
        "    inventory_events_df = pd.DataFrame(inventory_events)\n",
        "    inventory_events_df['event_date'] = pd.to_datetime(inventory_events_df['event_date'])\n",
        "    inventory_events_df = inventory_events_df.sort_values(by='event_date').reset_index(drop=True)\n",
        "    inventory_events_df['event_type'] = inventory_events_df['event_type'].astype('category')\n",
        "\n",
        "\n",
        "    inventory_records = []\n",
        "    current_inventory = {} # Key: (warehouse_id, product_id, batch_number), Value: {'quantity': X, 'expiry_date': Y}\n",
        "    waste_records = []\n",
        "    stockout_records = []\n",
        "\n",
        "    all_dates = sorted(inventory_events_df['event_date'].unique())\n",
        "\n",
        "    for current_date_np in all_dates:\n",
        "        current_date = pd.to_datetime(current_date_np)\n",
        "\n",
        "        #  Process Spoilage/Waste for the current date\n",
        "        expired_batches = []\n",
        "        for (wh_id, prod_id, batch_num), details in list(current_inventory.items()): # Use list() to iterate over a copy\n",
        "            if details['quantity'] > 0 and details['expiry_date'] and details['expiry_date'] <= current_date:\n",
        "                expired_batches.append(((wh_id, prod_id, batch_num), details['quantity']))\n",
        "\n",
        "        for (wh_id, prod_id, batch_num), expired_qty in expired_batches:\n",
        "            if current_inventory.get((wh_id, prod_id, batch_num), {}).get('quantity', 0) > 0:\n",
        "                wasted_amount = current_inventory[(wh_id, prod_id, batch_num)]['quantity']\n",
        "                waste_records.append({\n",
        "                    'waste_date': current_date,\n",
        "                    'warehouse_id': wh_id,\n",
        "                    'product_id': prod_id,\n",
        "                    'batch_number': batch_num,\n",
        "                    'wasted_quantity': wasted_amount,\n",
        "                    'reason': 'Expired'\n",
        "                })\n",
        "                current_inventory[(wh_id, prod_id, batch_num)]['quantity'] = 0\n",
        "\n",
        "        #  Process daily events\n",
        "        daily_events = inventory_events_df[inventory_events_df['event_date'] == current_date].copy()\n",
        "\n",
        "        for _, event in daily_events.iterrows():\n",
        "            product_id = event['product_id']\n",
        "            warehouse_id = event['warehouse_id']\n",
        "            quantity_change = event['quantity_change']\n",
        "            event_type = event['event_type']\n",
        "\n",
        "            if event_type in ['Receipt', 'Return_Receipt']:\n",
        "                batch_number = event['batch_number']\n",
        "                expiry_date = event['expiry_date']\n",
        "                key = (warehouse_id, product_id, batch_number)\n",
        "                if key not in current_inventory:\n",
        "                    current_inventory[key] = {'quantity': 0, 'expiry_date': expiry_date}\n",
        "                current_inventory[key]['quantity'] += quantity_change\n",
        "            elif event_type == 'Issue':\n",
        "                remaining_to_sell = abs(quantity_change)\n",
        "\n",
        "                available_batches = []\n",
        "                for (wh_id, prod_id, batch_num), details in current_inventory.items():\n",
        "                    if wh_id == warehouse_id and prod_id == product_id and details['quantity'] > 0:\n",
        "                        available_batches.append((details['expiry_date'], batch_num, details['quantity']))\n",
        "\n",
        "                available_batches.sort() # Sort by expiry date (FEFO)\n",
        "\n",
        "                total_available_for_product = sum(current_inventory.get((wh_id, prod_id, b_num), {}).get('quantity', 0)\n",
        "                                                  for (wh_id, prod_id, b_num), _ in current_inventory.items()\n",
        "                                                  if wh_id == warehouse_id and prod_id == product_id)\n",
        "\n",
        "                if remaining_to_sell > total_available_for_product:\n",
        "                    stockout_quantity = remaining_to_sell - total_available_for_product\n",
        "                    stockout_records.append({\n",
        "                        'stockout_date': current_date,\n",
        "                        'warehouse_id': warehouse_id,\n",
        "                        'product_id': product_id,\n",
        "                        'stockout_quantity': stockout_quantity\n",
        "                    })\n",
        "                    remaining_to_sell = total_available_for_product # Only sell what's available\n",
        "\n",
        "                for expiry_date_batch, batch_num, batch_quantity in available_batches:\n",
        "                    key = (warehouse_id, product_id, batch_num)\n",
        "                    if remaining_to_sell <= 0:\n",
        "                        break\n",
        "\n",
        "                    if current_inventory[key]['quantity'] >= remaining_to_sell:\n",
        "                        current_inventory[key]['quantity'] -= remaining_to_sell\n",
        "                        remaining_to_sell = 0\n",
        "                    else:\n",
        "                        remaining_to_sell -= current_inventory[key]['quantity']\n",
        "                        current_inventory[key]['quantity'] = 0\n",
        "\n",
        "        # Record current inventory state for this date\n",
        "        for (wh_id, prod_id, batch_num), details in current_inventory.items():\n",
        "            if details['quantity'] > 0:\n",
        "                inventory_records.append({\n",
        "                    'snapshot_date': current_date,\n",
        "                    'warehouse_id': wh_id,\n",
        "                    'product_id': prod_id,\n",
        "                    'batch_number': batch_num,\n",
        "                    'quantity_on_hand': details['quantity'],\n",
        "                    'expiry_date': details['expiry_date']\n",
        "                })\n",
        "\n",
        "    inventory_df = pd.DataFrame(inventory_records)\n",
        "    inventory_df['snapshot_date'] = pd.to_datetime(inventory_df['snapshot_date'])\n",
        "    inventory_df['expiry_date'] = pd.to_datetime(inventory_df['expiry_date'])\n",
        "    inventory_df = inventory_df.sort_values(by=['snapshot_date', 'warehouse_id', 'product_id', 'expiry_date']).reset_index(drop=True)\n",
        "    inventory_df = inventory_df.drop_duplicates(subset=['snapshot_date', 'warehouse_id', 'product_id', 'batch_number'], keep='last')\n",
        "\n",
        "    waste_df = pd.DataFrame(waste_records)\n",
        "    if not waste_df.empty:\n",
        "        waste_df['waste_date'] = pd.to_datetime(waste_df['waste_date'])\n",
        "        waste_df['reason'] = waste_df['reason'].astype('category')\n",
        "\n",
        "    stockout_df = pd.DataFrame(stockout_records)\n",
        "    if not stockout_df.empty:\n",
        "        stockout_df['stockout_date'] = pd.to_datetime(stockout_df['stockout_date'])\n",
        "\n",
        "    return inventory_df, waste_df, stockout_df"
      ],
      "metadata": {
        "id": "ZnK5TwcaxFGS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    NUM_PRODUCTS = 5000\n",
        "    NUM_WAREHOUSES = 10\n",
        "    NUM_SUPPLIERS = 50\n",
        "    NUM_CUSTOMERS = 1000\n",
        "    NUM_PURCHASE_ORDERS = 10000\n",
        "    NUM_SALES_RECORDS = 50000\n",
        "    NUM_RETURNS = int(NUM_SALES_RECORDS * 0.05) # 5% of sales are returned\n",
        "\n",
        "    START_DATE = datetime.now() - timedelta(days=2*365)\n",
        "    END_DATE = datetime.now()\n",
        "\n",
        "\n",
        "    products_df = generate_products_df(NUM_PRODUCTS, fake)\n",
        "    print(\"products_df\")\n",
        "    print(products_df.head())\n",
        "\n",
        "    warehouses_df = generate_warehouses_df(NUM_WAREHOUSES)\n",
        "    print(\"\\nwarehouses_df\")\n",
        "    print(warehouses_df.head())\n",
        "\n",
        "    suppliers_df = generate_suppliers_df(NUM_SUPPLIERS, fake)\n",
        "    print(\"\\nsuppliers_df\")\n",
        "    print(suppliers_df.head())\n",
        "\n",
        "    purchase_orders_df = generate_purchase_orders_df(NUM_PURCHASE_ORDERS, products_df, suppliers_df, START_DATE, END_DATE)\n",
        "    print(\"\\npurchase_orders_df\")\n",
        "    print(purchase_orders_df.head())\n",
        "\n",
        "    customers_df = generate_customers_df(NUM_CUSTOMERS, fake)\n",
        "    print(\"\\ncustomers_df\")\n",
        "    print(customers_df.head())\n",
        "\n",
        "    sales_df = generate_sales_df(NUM_SALES_RECORDS, products_df, customers_df, warehouses_df, START_DATE, END_DATE)\n",
        "    print(\"\\nsales_df\")\n",
        "    print(sales_df.head())\n",
        "\n",
        "    returns_df = generate_returns_df(sales_df, NUM_RETURNS)\n",
        "    print(\"\\nreturns_df\")\n",
        "    print(returns_df.head())\n",
        "\n",
        "    inventory_df, waste_df, stockout_df = simulate_inventory_and_waste(purchase_orders_df, sales_df, returns_df, products_df, warehouses_df, START_DATE, END_DATE)\n",
        "    print(\"\\ninventory_df\")\n",
        "    print(inventory_df.head())\n",
        "\n",
        "    if not waste_df.empty:\n",
        "        print(\"\\nwaste_df (Spoilage)\")\n",
        "        print(waste_df.head())\n",
        "    else:\n",
        "        print(\"\\nNo Waste (Spoilage) records generated.\")\n",
        "\n",
        "    if not stockout_df.empty:\n",
        "        print(\"\\nstockout_df\")\n",
        "        print(stockout_df.head())\n",
        "    else:\n",
        "        print(\"\\nNo Stockout records generated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoKhxZEixFJL",
        "outputId": "406885c8-09a4-47a6-d086-958e699727bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "products_df\n",
            "   product_id           product_name        product_category  unit_price  \\\n",
            "0  PROD_00001         LA-926 mg star       Ophthalmic & Otic       29.16   \n",
            "1  PROD_00002         Tablet let but  Vitamins & Supplements        7.71   \n",
            "2  PROD_00003  Syrup account believe                Hormonal       62.92   \n",
            "3  PROD_00004     Tablet whether yes           Diabetic Care       15.57   \n",
            "4  PROD_00005      AQ-595 unit wrong           Diabetic Care       11.24   \n",
            "\n",
            "   avg_shelf_life_days           storage_conditions  \n",
            "0                 1095             Room Temperature  \n",
            "1                 1460  Protect from Light/Moisture  \n",
            "2                 1095             Room Temperature  \n",
            "3                  730             Room Temperature  \n",
            "4                 1095                 Cold Storage  \n",
            "\n",
            "warehouses_df\n",
            "  warehouse_id             warehouse_name warehouse_city  latitude  longitude  \\\n",
            "0        WH_01   Central Warehouse Tehran         Tehran   35.6892    51.3890   \n",
            "1        WH_02  Central Warehouse Mashhad        Mashhad   36.2605    59.6168   \n",
            "2        WH_03  Central Warehouse Isfahan        Isfahan   32.6546    51.6670   \n",
            "3        WH_04   Central Warehouse Tabriz         Tabriz   38.0805    46.2918   \n",
            "4        WH_05   Central Warehouse Shiraz         Shiraz   29.6065    52.5414   \n",
            "\n",
            "   capacity_units  \n",
            "0         6897697  \n",
            "1         3557066  \n",
            "2         2053216  \n",
            "3         3579886  \n",
            "4         1612674  \n",
            "\n",
            "suppliers_df\n",
            "  supplier_id       supplier_name supplier_location  avg_lead_time_days  \\\n",
            "0     SUP_001       Hernandez PLC      Sanchezville                  13   \n",
            "1     SUP_002           Cox-Dixon  Lake Melissaport                   9   \n",
            "2     SUP_003   Gonzalez-Johnston        West Tracy                  17   \n",
            "3     SUP_004          Bird-Moore        Jamesshire                  27   \n",
            "4     SUP_005  Gonzalez-Hernandez        Weaverland                  17   \n",
            "\n",
            "   reliability_score  \n",
            "0               0.85  \n",
            "1               0.71  \n",
            "2               0.97  \n",
            "3               0.72  \n",
            "4               0.77  \n",
            "\n",
            "purchase_orders_df\n",
            "      po_id                    po_date supplier_id  product_id  \\\n",
            "0  PO_00000 2024-06-15 10:09:01.559545     SUP_048  PROD_00127   \n",
            "1  PO_00001 2024-04-23 10:09:01.559545     SUP_046  PROD_04537   \n",
            "2  PO_00002 2024-05-27 10:09:01.559545     SUP_006  PROD_03554   \n",
            "3  PO_00003 2024-01-05 10:09:01.559545     SUP_049  PROD_04556   \n",
            "4  PO_00004 2024-12-31 10:09:01.559545     SUP_020  PROD_02280   \n",
            "\n",
            "   ordered_quantity  unit_cost     expected_delivery_date  \\\n",
            "0              1689   8.422099 2024-07-07 10:09:01.559545   \n",
            "1              2409   3.497560 2024-05-09 10:09:01.559545   \n",
            "2               806  12.826352 2024-06-15 10:09:01.559545   \n",
            "3               401   7.446941 2024-01-17 10:09:01.559545   \n",
            "4               331  15.578058 2025-01-13 10:09:01.559545   \n",
            "\n",
            "        actual_delivery_date delivery_status  \n",
            "0 2024-07-07 10:09:01.559545       Delivered  \n",
            "1 2024-05-09 10:09:01.559545       Delivered  \n",
            "2 2024-06-16 10:09:01.559545         Delayed  \n",
            "3 2024-01-17 10:09:01.559545       Delivered  \n",
            "4 2025-01-13 10:09:01.559545       Delivered  \n",
            "\n",
            "customers_df\n",
            "  customer_id           customer_name      customer_location\n",
            "0   CUST_0001    Thomas-Diaz Pharmacy              Lopezbury\n",
            "1   CUST_0002   Cooper-Small Pharmacy        Port Stevenberg\n",
            "2   CUST_0003  Rodriguez PLC Pharmacy          Hernandezside\n",
            "3   CUST_0004   Garrison PLC Pharmacy  South Christopherview\n",
            "4   CUST_0005   Wright-Bates Pharmacy               Ryanbury\n",
            "\n",
            "sales_df\n",
            "      sales_id                 sales_date customer_id warehouse_id  \\\n",
            "0  SALE_000000 2024-01-15 10:09:01.559545   CUST_0419        WH_04   \n",
            "1  SALE_000001 2024-11-30 10:09:01.559545   CUST_0436        WH_06   \n",
            "2  SALE_000002 2025-06-27 10:09:01.559545   CUST_0444        WH_04   \n",
            "3  SALE_000003 2023-08-19 10:09:01.559545   CUST_0425        WH_10   \n",
            "4  SALE_000004 2024-01-22 10:09:01.559545   CUST_0632        WH_02   \n",
            "\n",
            "   product_id  sold_quantity  sales_price  delivery_time_hours  \n",
            "0  PROD_04337             30       846.90                   20  \n",
            "1  PROD_02819              7       103.60                    6  \n",
            "2  PROD_01468              7       402.78                   37  \n",
            "3  PROD_00596             21       412.86                   18  \n",
            "4  PROD_04946             22      1135.64                   25  \n",
            "\n",
            "returns_df\n",
            "   return_id     sales_id                return_date  product_id warehouse_id  \\\n",
            "0  RET_00000  SALE_040712 2024-07-14 10:09:01.559545  PROD_03517        WH_02   \n",
            "1  RET_00001  SALE_043377 2023-09-29 10:09:01.559545  PROD_02545        WH_01   \n",
            "2  RET_00002  SALE_006515 2023-08-24 10:09:01.559545  PROD_04410        WH_10   \n",
            "3  RET_00003  SALE_047170 2023-08-25 10:09:01.559545  PROD_02372        WH_03   \n",
            "4  RET_00004  SALE_037449 2025-05-18 10:09:01.559545  PROD_02512        WH_08   \n",
            "\n",
            "   returned_quantity             return_reason  \n",
            "0                  2     Customer changed mind  \n",
            "1                  7  Expired product received  \n",
            "2                  2        Damaged in transit  \n",
            "3                  1     Customer changed mind  \n",
            "4                  5  Expired product received  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV (for easy viewing)\n",
        "    products_df.to_csv('products.csv', index=False)\n",
        "    warehouses_df.to_csv('warehouses.csv', index=False)\n",
        "    suppliers_df.to_csv('suppliers.csv', index=False)\n",
        "    customers_df.to_csv('customers.csv', index=False)\n",
        "    purchase_orders_df.to_csv('purchase_orders.csv', index=False)\n",
        "    sales_df.to_csv('sales.csv', index=False)\n",
        "    returns_df.to_csv('returns.csv', index=False)\n",
        "    inventory_df.to_csv('inventory.csv', index=False)\n",
        "    waste_df.to_csv('waste.csv', index=False)\n",
        "    stockout_df.to_csv('stockouts.csv', index=False)\n",
        "\n",
        "\n",
        "    products_df.to_parquet('products.parquet', index=False)\n",
        "    warehouses_df.to_parquet('warehouses.parquet', index=False)\n",
        "    suppliers_df.to_parquet('suppliers.parquet', index=False)\n",
        "    customers_df.to_parquet('customers.parquet', index=False)\n",
        "    purchase_orders_df.to_parquet('purchase_orders.parquet', index=False)\n",
        "    sales_df.to_parquet('sales.parquet', index=False)\n",
        "    returns_df.to_parquet('returns.parquet', index=False)\n",
        "    inventory_df.to_parquet('inventory.parquet', index=False)\n",
        "    waste_df.to_parquet('waste.parquet', index=False)\n",
        "    stockout_df.to_parquet('stockouts.parquet', index=False)"
      ],
      "metadata": {
        "id": "VIjpSE40xFLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxlr5KGttXjZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}